{"train/loss": 0.0161, "train/learning_rate": 0.0, "train/rewards/chosen": -0.6995437145233154, "train/rewards/rejected": -8.308011054992676, "train/rewards/accuracies": 1.0, "train/rewards/margins": 7.608466625213623, "train/logps/rejected": -280.884765625, "train/logps/chosen": -209.1072235107422, "train/logits/rejected": -2.9149153232574463, "train/logits/chosen": -2.682051420211792, "train/epoch": 0.9978008168394596, "train/global_step": 397, "_timestamp": 1718053822.8729677, "_runtime": 20759.99065876007, "_step": 400, "eval/loss": 0.019466891884803772, "eval/runtime": 105.3962, "eval/samples_per_second": 1.224, "eval/steps_per_second": 0.313, "eval/rewards/chosen": -0.8876842856407166, "eval/rewards/rejected": -8.337570190429688, "eval/rewards/accuracies": 1.0, "eval/rewards/margins": 7.449885845184326, "eval/logps/rejected": -303.2828674316406, "eval/logps/chosen": -185.32777404785156, "eval/logits/rejected": -3.1485328674316406, "eval/logits/chosen": -3.100538492202759, "train_runtime": 20634.9717, "train_samples_per_second": 0.617, "train_steps_per_second": 0.019, "total_flos": 0.0, "train_loss": 0.0797450426585916, "_wandb": {"runtime": 20982}}