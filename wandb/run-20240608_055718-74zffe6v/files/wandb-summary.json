{"train/loss": 0.1179, "train/learning_rate": 0.0, "train/rewards/chosen": -1.2876530885696411, "train/rewards/rejected": -4.9204559326171875, "train/rewards/accuracies": 0.9375, "train/rewards/margins": 3.632803201675415, "train/logps/rejected": -358.57305908203125, "train/logps/chosen": -265.9736328125, "train/logits/rejected": -2.356771469116211, "train/logits/chosen": -1.7242145538330078, "train/epoch": 0.9992144540455616, "train/global_step": 795, "_timestamp": 1717829753.1531215, "_runtime": 3514.258763551712, "_step": 802, "eval/loss": 0.06242619827389717, "eval/runtime": 13.5724, "eval/samples_per_second": 9.505, "eval/steps_per_second": 4.789, "eval/rewards/chosen": -1.3961278200149536, "eval/rewards/rejected": -5.676170349121094, "eval/rewards/accuracies": 1.0, "eval/rewards/margins": 4.280043125152588, "eval/logps/rejected": -380.7641906738281, "eval/logps/chosen": -272.5064697265625, "eval/logits/rejected": -2.975144386291504, "eval/logits/chosen": -2.705693006515503, "train_runtime": 3456.4843, "train_samples_per_second": 3.683, "train_steps_per_second": 0.23, "total_flos": 0.0, "train_loss": 0.17071479043730026, "_wandb": {"runtime": 3671}}