2024-06-10 15:24:21,432 - Hyperparameters:
2024-06-10 15:24:21,432 - exp_name: DPO
2024-06-10 15:24:21,432 - model_name: unsloth/mistral-7b-v0.3-bnb-4bit
2024-06-10 15:24:21,432 - train: True
2024-06-10 15:24:21,432 - inference_base_model: False
2024-06-10 15:24:21,432 - wandb_token: 0aad23b14e9c1e0e2342caaefbcf3c240a8a3e5e
2024-06-10 15:24:21,432 - train_batch_size: 4
2024-06-10 15:24:21,432 - eval_batch_size: 4
2024-06-10 15:24:21,432 - gradient_accumulation_steps: 8
2024-06-10 15:24:21,432 - lr: 5e-06
2024-06-10 15:24:21,432 - lr_scheduler_type: cosine
2024-06-10 15:24:21,432 - max_steps: 0
2024-06-10 15:24:21,432 - num_epochs: 1
2024-06-10 15:24:21,432 - optimizer: paged_adamw_32bit
2024-06-10 15:24:21,432 - weight_decay: 0
2024-06-10 15:24:21,432 - max_grad_norm: 0
2024-06-10 15:24:21,432 - warmup_ratio: 0
2024-06-10 15:24:21,432 - beta: 0.1
2024-06-10 15:24:21,432 - max_length: 1024
2024-06-10 15:24:21,432 - max_prompt_length: 512
2024-06-10 15:24:21,432 - seed: 2024
2024-06-10 15:24:21,432 - logging_strategy: steps
2024-06-10 15:24:21,432 - logging_steps: 1
2024-06-10 15:24:21,432 - evaluation_strategy: steps
2024-06-10 15:24:21,432 - eval_steps: 100
2024-06-10 15:24:21,432 - output_dir: ./outputs
2024-06-10 15:24:21,432 - save_strategy: epoch
2024-06-10 15:24:21,432 - report_to: wandb
