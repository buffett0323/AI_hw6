2024-06-08 05:46:45,604 - Hyperparameters:
2024-06-08 05:46:45,604 - exp_name: DPO
2024-06-08 05:46:45,604 - model_name: unsloth/tinyllama-bnb-4bit
2024-06-08 05:46:45,604 - train: True
2024-06-08 05:46:45,604 - inference_base_model: False
2024-06-08 05:46:45,604 - wandb_token: 0aad23b14e9c1e0e2342caaefbcf3c240a8a3e5e
2024-06-08 05:46:45,604 - train_batch_size: 2
2024-06-08 05:46:45,604 - eval_batch_size: 2
2024-06-08 05:46:45,604 - gradient_accumulation_steps: 8
2024-06-08 05:46:45,604 - lr: 5e-06
2024-06-08 05:46:45,604 - lr_scheduler_type: cosine
2024-06-08 05:46:45,604 - max_steps: 0
2024-06-08 05:46:45,604 - num_epochs: 1
2024-06-08 05:46:45,604 - optimizer: paged_adamw_32bit
2024-06-08 05:46:45,604 - weight_decay: 0
2024-06-08 05:46:45,604 - max_grad_norm: 0
2024-06-08 05:46:45,604 - warmup_ratio: 0
2024-06-08 05:46:45,604 - beta: 0.1
2024-06-08 05:46:45,604 - max_length: 1024
2024-06-08 05:46:45,604 - max_prompt_length: 512
2024-06-08 05:46:45,604 - seed: 2024
2024-06-08 05:46:45,604 - logging_strategy: steps
2024-06-08 05:46:45,604 - logging_steps: 1
2024-06-08 05:46:45,604 - evaluation_strategy: steps
2024-06-08 05:46:45,604 - eval_steps: 100
2024-06-08 05:46:45,604 - output_dir: ./outputs
2024-06-08 05:46:45,604 - save_strategy: epoch
2024-06-08 05:46:45,604 - report_to: wandb
