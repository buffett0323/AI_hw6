2024-06-11 04:05:23,580 - Hyperparameters:
2024-06-11 04:05:23,580 - exp_name: ORPO
2024-06-11 04:05:23,580 - model_name: unsloth/mistral-7b-v0.3-bnb-4bit
2024-06-11 04:05:23,580 - train: True
2024-06-11 04:05:23,580 - inference_base_model: False
2024-06-11 04:05:23,580 - wandb_token: 0aad23b14e9c1e0e2342caaefbcf3c240a8a3e5e
2024-06-11 04:05:23,580 - train_batch_size: 4
2024-06-11 04:05:23,580 - eval_batch_size: 4
2024-06-11 04:05:23,580 - gradient_accumulation_steps: 8
2024-06-11 04:05:23,580 - lr: 5e-06
2024-06-11 04:05:23,580 - lr_scheduler_type: cosine
2024-06-11 04:05:23,580 - max_steps: 0
2024-06-11 04:05:23,580 - num_epochs: 1
2024-06-11 04:05:23,580 - optimizer: paged_adamw_32bit
2024-06-11 04:05:23,580 - weight_decay: 0
2024-06-11 04:05:23,580 - max_grad_norm: 0
2024-06-11 04:05:23,580 - warmup_ratio: 0
2024-06-11 04:05:23,580 - beta: 0.1
2024-06-11 04:05:23,580 - max_length: 1024
2024-06-11 04:05:23,581 - max_prompt_length: 512
2024-06-11 04:05:23,581 - seed: 2024
2024-06-11 04:05:23,581 - logging_strategy: steps
2024-06-11 04:05:23,581 - logging_steps: 1
2024-06-11 04:05:23,581 - evaluation_strategy: steps
2024-06-11 04:05:23,581 - eval_steps: 100
2024-06-11 04:05:23,581 - output_dir: ./outputs
2024-06-11 04:05:23,581 - save_strategy: epoch
2024-06-11 04:05:23,581 - report_to: wandb
