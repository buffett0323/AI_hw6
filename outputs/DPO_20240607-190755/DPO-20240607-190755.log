2024-06-07 19:07:55,723 - Hyperparameters:
2024-06-07 19:07:55,724 - exp_name: DPO
2024-06-07 19:07:55,724 - model_name: unsloth/mistral-7b-v0.3-bnb-4bit
2024-06-07 19:07:55,725 - train: True
2024-06-07 19:07:55,725 - inference_base_model: False
2024-06-07 19:07:55,725 - wandb_token: 0aad23b14e9c1e0e2342caaefbcf3c240a8a3e5e
2024-06-07 19:07:55,726 - train_batch_size: 2
2024-06-07 19:07:55,726 - eval_batch_size: 2
2024-06-07 19:07:55,726 - gradient_accumulation_steps: 8
2024-06-07 19:07:55,727 - lr: 5e-06
2024-06-07 19:07:55,727 - lr_scheduler_type: cosine
2024-06-07 19:07:55,727 - max_steps: 0
2024-06-07 19:07:55,727 - num_epochs: 1
2024-06-07 19:07:55,728 - optimizer: paged_adamw_32bit
2024-06-07 19:07:55,728 - weight_decay: 0
2024-06-07 19:07:55,729 - max_grad_norm: 0
2024-06-07 19:07:55,729 - warmup_ratio: 0
2024-06-07 19:07:55,729 - beta: 0.1
2024-06-07 19:07:55,730 - max_length: 1024
2024-06-07 19:07:55,730 - max_prompt_length: 512
2024-06-07 19:07:55,730 - seed: 2024
2024-06-07 19:07:55,731 - logging_strategy: steps
2024-06-07 19:07:55,731 - logging_steps: 1
2024-06-07 19:07:55,731 - evaluation_strategy: steps
2024-06-07 19:07:55,732 - eval_steps: 100
2024-06-07 19:07:55,732 - output_dir: ./outputs
2024-06-07 19:07:55,732 - save_strategy: epoch
2024-06-07 19:07:55,732 - report_to: wandb
