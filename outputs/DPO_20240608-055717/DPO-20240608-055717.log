2024-06-08 05:57:17,475 - Hyperparameters:
2024-06-08 05:57:17,475 - exp_name: DPO
2024-06-08 05:57:17,475 - model_name: unsloth/tinyllama-bnb-4bit
2024-06-08 05:57:17,475 - train: True
2024-06-08 05:57:17,475 - inference_base_model: False
2024-06-08 05:57:17,475 - wandb_token: 0aad23b14e9c1e0e2342caaefbcf3c240a8a3e5e
2024-06-08 05:57:17,475 - train_batch_size: 2
2024-06-08 05:57:17,475 - eval_batch_size: 2
2024-06-08 05:57:17,475 - gradient_accumulation_steps: 8
2024-06-08 05:57:17,475 - lr: 5e-06
2024-06-08 05:57:17,475 - lr_scheduler_type: cosine
2024-06-08 05:57:17,475 - max_steps: 0
2024-06-08 05:57:17,475 - num_epochs: 1
2024-06-08 05:57:17,475 - optimizer: paged_adamw_32bit
2024-06-08 05:57:17,475 - weight_decay: 0
2024-06-08 05:57:17,475 - max_grad_norm: 0
2024-06-08 05:57:17,475 - warmup_ratio: 0
2024-06-08 05:57:17,475 - beta: 0.1
2024-06-08 05:57:17,475 - max_length: 1024
2024-06-08 05:57:17,475 - max_prompt_length: 512
2024-06-08 05:57:17,475 - seed: 2024
2024-06-08 05:57:17,475 - logging_strategy: steps
2024-06-08 05:57:17,475 - logging_steps: 1
2024-06-08 05:57:17,475 - evaluation_strategy: steps
2024-06-08 05:57:17,475 - eval_steps: 100
2024-06-08 05:57:17,475 - output_dir: ./outputs
2024-06-08 05:57:17,475 - save_strategy: epoch
2024-06-08 05:57:17,475 - report_to: wandb
